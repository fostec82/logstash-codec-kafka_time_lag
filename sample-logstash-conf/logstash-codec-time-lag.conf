input {
    ...
}

filter {

    mutate {
        add_field => { 
            "[@metadata][KAFKA_TIME_MACHINE_SINK_TOPIC_NAME]" => "metrics_ktm_logs"
            "[@metadata][kafka_datacenter_producer]"          => "kafka_datacenter_producer"
            "[@metadata][kafka_topic_producer]"               => "kafka_topic_producer"
            "[@metadata][kafka_consumer_group_producer]"      => "kafka_consumer_group_producer_chris"
            "[@metadata][kafka_append_time_producer]"         => 100
            "[@metadata][logstash_kafka_read_time_producer]"  => "200"
            "[@metadata][kafka_datacenter_aggregate]"         => "kafka_datacenter_aggregate"
            "[@metadata][kafka_topic_aggregate]"              => "kafka_topic_aggregate"
            "[@metadata][kafka_consumer_group_aggregate]"     => "kafka_consumer_group_aggregate"
            "[@metadata][kafka_append_time_aggregate]"        => "300"
        }
    }

    ruby {
        code => 'logstash_kafka_read_time_aggregate = (Time.now.to_f * 1000).to_i
                event.set( "[@metadata][logstash_kafka_read_time_aggregate]", logstash_kafka_read_time_aggregate )'
    }

    ....
}

output {

    if ([@metadata][KAFKA_TIME_MACHINE_SINK_TOPIC_NAME]) {
        kafka {
            topic_id                  => "%{[@metadata][KAFKA_TIME_MACHINE_SINK_TOPIC_NAME]}"
            bootstrap_servers         => "lmabufaiad2-kf.intlma.wbx2.com:9093"
            id                        => "metrics-lmabufottaint6-to-lmabufaiad2-shipper-kafka-out0"
            compression_type          => "gzip"
            batch_size                => "15000"
            linger_ms                 => "100"
            buffer_memory             => "67108864"

            security_protocol         => "SSL"
            ssl_truststore_location   => "/etc/logstash/ssl/client.truststore.jks"
            ssl_truststore_password   => "WB6ZT5"
            ssl_keystore_location     => "/etc/logstash/ssl/client.keystore.jks"
            ssl_keystore_password     => "0IHQN7"

            retries         => 5

            key_serializer            => "org.apache.kafka.common.serialization.ByteArraySerializer"
            value_serializer          => "org.apache.kafka.common.serialization.ByteArraySerializer"
            codec => kafkatimelag {}
        }
    }

    if  "diagnostics" in [tags] {
        elasticsearch {
        hosts              => ["role-data.logs6aiad2-es-app.service.consul:9200"]
        ilm_enabled        => true
        ilm_rollover_alias => "logstash-app-diagnostics-ilm"
        ilm_policy         => "logstash-app-diagnostics"
        ilm_pattern        => "{now/d}-000001"
        id                 => "indexer-lmabufaiad2-app-elasticsearch-out-diagnostics-alias"
        manage_template    => false

        # user/password
        user               => "logstash"
        password           => "YE7Ta4aHOaYaf0yU"
        sniffing         => true
        }
    } else if "metrics" in [tags] {
        elasticsearch {
        hosts              => ["role-data.logs6aiad2-es-app.service.consul:9200"]
        ilm_enabled        => true
        ilm_rollover_alias => "logstash-app-metrics-ilm"
        ilm_policy         => "logstash-app-metrics"
        ilm_pattern        => "{now/d}-000001"
        id                 => "indexer-lmabufaiad2-app-elasticsearch-out-metrics-alias"
        manage_template    => false

        # user/password
        user               => "logstash"
        password           => "YE7Ta4aHOaYaf0yU"
        sniffing         => true
        }
    } else {
        elasticsearch {
            hosts              => ["role-data.logs6aiad2-es-app.service.consul:9200"]
            index              => "%{[@metadata][AGGREGATION_SINK_INDEX]}"
            id                 => "indexer-lmabufaiad2-app-elasticsearch-out"
            manage_template    => false

            # user/password
            user               => "logstash"
            password           => "YE7Ta4aHOaYaf0yU"
            sniffing         => true
        }
    }   
}